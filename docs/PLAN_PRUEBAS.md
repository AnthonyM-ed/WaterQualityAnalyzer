# Plan de Pruebas - Sistema de Monitoreo de Calidad del Agua

## Objetivo General
Validar que el sistema cumple con los requisitos de funcionalidad, rendimiento, usabilidad y accesibilidad para garantizar una gesti√≥n eficiente de datos y monitorizaci√≥n en tiempo real.

---

## 1. Pruebas de Mejora en Gesti√≥n de Datos y Monitorizaci√≥n

### 1.1 Pruebas de Tiempo Real y Actualizaci√≥n de Datos

#### PT-001: Latencia de Actualizaci√≥n de Sensores
**Objetivo**: Verificar que las lecturas se actualicen cada 30 segundos  
**Tipo**: Funcional + Rendimiento

**Procedimiento**:
1. Iniciar la aplicaci√≥n en modo tiempo real
2. Observar el dashboard con las 3 estaciones
3. Cronometrar el tiempo entre actualizaciones consecutivas
4. Registrar 10 ciclos de actualizaci√≥n

**Criterios de √âxito**:
- Intervalo entre lecturas: 30s ¬± 2s
- No se pierden actualizaciones durante 10 minutos
- UI responde en <200ms tras recibir datos

**M√©tricas**:
```
Tiempo promedio entre lecturas: _____ segundos
Actualizaciones exitosas: _____ / 20
Tiempo de renderizado UI: _____ ms
```

---

#### PT-002: Sincronizaci√≥n Firebase en Tiempo Real
**Objetivo**: Validar que los datos se guardan inmediatamente en Firebase  
**Tipo**: Integraci√≥n

**Procedimiento**:
1. Abrir Firebase Console en navegador
2. Ejecutar app en dispositivo con conexi√≥n WiFi
3. Observar dashboard y consola Firebase simult√°neamente
4. Verificar que cada lectura aparece en Firebase al momento

**Criterios de √âxito**:
- Datos visibles en Firebase <3s despu√©s de generarse
- Estructura correcta: `readings/{stationId}/{timestamp}`
- Campo `latest` se actualiza correctamente

**M√©tricas**:
```
Latencia de sincronizaci√≥n promedio: _____ ms
Lecturas perdidas: _____ / 50
Consistencia de estructura: _____ %
```

---

#### PT-003: Persistencia Offline y Resincronizaci√≥n
**Objetivo**: Verificar que el modo offline funciona correctamente  
**Tipo**: Integraci√≥n + Resiliencia

**Procedimiento**:
1. Iniciar app con conexi√≥n activa
2. Esperar 2 minutos (4 lecturas generadas)
3. Desactivar WiFi y datos m√≥viles
4. Esperar 3 minutos m√°s (6 lecturas en cach√©)
5. Reactivar conexi√≥n
6. Verificar en Firebase que las 6 lecturas se sincronizaron

**Criterios de √âxito**:
- App funciona sin errores en modo offline
- Cach√© almacena al menos 100 lecturas
- Al reconectar, todas las lecturas se sincronizan en <30s
- No hay duplicados en Firebase

**M√©tricas**:
```
Lecturas almacenadas offline: _____ / 6
Tiempo de resincronizaci√≥n: _____ segundos
Lecturas duplicadas: _____ (debe ser 0)
Errores reportados: _____ (debe ser 0)
```

---

### 1.2 Pruebas de Optimizaci√≥n de Recursos

#### PT-004: Consumo de Memoria
**Objetivo**: Validar que la app no consume memoria excesiva  
**Tipo**: Rendimiento

**Procedimiento**:
1. Abrir Android Studio Profiler (o equivalente)
2. Ejecutar app en modo Release
3. Dejar funcionando 30 minutos en modo tiempo real
4. Alternar entre pantallas (Dashboard, Gr√°ficos)
5. Cargar gr√°fico de 90 d√≠as (m√°ximo volumen de datos)
6. Registrar memoria promedio y picos

**Criterios de √âxito**:
- Memoria promedio: <150MB
- Sin memory leaks (gr√°fico estable)
- Picos transitorios <200MB
- GC (Garbage Collection) no causa lag perceptible

**M√©tricas**:
```
Memoria promedio: _____ MB
Memoria m√°xima: _____ MB
Incremento de memoria en 30 min: _____ MB
Frecuencia de GC: _____ veces/minuto
```

---

#### PT-005: Rendimiento de Gr√°ficos con Datasets Grandes
**Objetivo**: Verificar que los gr√°ficos mantienen fluidez con muchos datos  
**Tipo**: Rendimiento

**Procedimiento**:
1. Cargar gr√°fico de 90 d√≠as (m√°ximo datos hist√≥ricos)
2. Medir frames por segundo (FPS) durante scroll
3. Cambiar entre diferentes m√©tricas (pH, TDS, Turbidez)
4. Alternar entre estaciones
5. Usar herramienta Flutter DevTools > Performance

**Criterios de √âxito**:
- FPS: ‚â•55 (en pantalla 60Hz)
- Tiempo de carga de gr√°fico: <2s
- Sin frames perdidos durante scroll
- Muestreo inteligente activo (m√°ximo 50 puntos para 24h)

**M√©tricas**:
```
FPS promedio: _____ fps
Tiempo de carga 90d: _____ ms
Frames perdidos: _____ (debe ser 0)
Puntos renderizados (24h): _____ (m√°ximo 50)
```

---

#### PT-006: Eficiencia de Consultas Firebase
**Objetivo**: Medir la eficiencia de las consultas a Firebase  
**Tipo**: Rendimiento + Costos

**Procedimiento**:
1. Abrir Firebase Console > Database > Usage
2. Cargar gr√°ficos hist√≥ricos para las 3 estaciones
3. Anotar cantidad de lecturas descargadas
4. Verificar que no se descargan datos innecesarios
5. Revisar logs de consultas en Flutter

**Criterios de √âxito**:
- Consulta 24h: <100 lecturas por estaci√≥n
- Consulta 90d: Solo datos del rango solicitado
- Sin consultas duplicadas en <5 minutos
- Filtrado en memoria (no m√∫ltiples queries)

**M√©tricas**:
```
Lecturas descargadas (24h): _____ / estaci√≥n
Lecturas descargadas (90d): _____ / estaci√≥n
Consultas Firebase en 5 min: _____ 
Datos filtrados en cliente: _____ %
```

---

### 1.3 Pruebas de Precisi√≥n de Datos

#### PT-007: Validaci√≥n de Umbrales de Calidad
**Objetivo**: Verificar que los indicadores de calidad son correctos  
**Tipo**: Funcional

**Procedimiento**:
1. Revisar datos hist√≥ricos en Firebase
2. Seleccionar 10 lecturas aleatorias
3. Calcular manualmente el estado (verde/amarillo/rojo)
4. Comparar con la UI de la app

**Valores de Referencia**:
```
pH: 6.5-8.5 (verde), fuera de rango (rojo)
TDS: <200 (verde), 200-300 (amarillo), >300 (rojo)
Turbidez: <3 (verde), 3-5 (amarillo), >5 (rojo)
Temperatura: 15-30¬∞C (verde), fuera de rango (amarillo)
```

**Criterios de √âxito**:
- 100% de coincidencia entre c√°lculo manual y UI
- Cambios de estado reflejan inmediatamente en UI
- Iconos de estado correctos (‚úì / ‚ö† / ‚úó)

**M√©tricas**:
```
Coincidencias: _____ / 10
Tiempo de actualizaci√≥n visual: _____ ms
Errores de clasificaci√≥n: _____ (debe ser 0)
```

---

#### PT-008: Integridad de Datos CSV vs Firebase
**Objetivo**: Validar que la migraci√≥n CSV ‚Üí Firebase fue correcta  
**Tipo**: Integridad de Datos

**Procedimiento**:
1. Ejecutar script `migrate_csv_to_firebase.dart`
2. Contar lecturas en archivo CSV original
3. Consultar Firebase y contar lecturas migradas
4. Comparar 5 lecturas aleatorias (valores exactos)

**Criterios de √âxito**:
- Cantidad de lecturas: CSV = Firebase
- Valores coinciden al 100% (pH, TDS, turbidez, temp)
- Timestamps ajustados correctamente a 2025
- Sin lecturas duplicadas

**M√©tricas**:
```
Lecturas CSV: _____ 
Lecturas Firebase: _____
Coincidencia de valores: _____ / 5
Duplicados encontrados: _____ (debe ser 0)
```

---

## 2. Pruebas de Usabilidad y Accesibilidad

### 2.1 Pruebas de Interfaz Intuitiva

#### PT-009: Tiempo de Aprendizaje (First-Time Users)
**Objetivo**: Medir qu√© tan r√°pido un usuario nuevo entiende la app  
**Tipo**: Usabilidad

**Procedimiento**:
1. Seleccionar 5 usuarios sin experiencia previa
2. Darles solo una descripci√≥n breve: "App para monitorear calidad del agua"
3. Pedirles completar las siguientes tareas SIN ayuda:
   - Registrarse y hacer login
   - Ver datos de la estaci√≥n CA-08
   - Cambiar a gr√°ficos hist√≥ricos
   - Ver datos de los √∫ltimos 30 d√≠as
   - Interpretar si el agua est√° en buen estado
4. Cronometrar tiempo por tarea

**Criterios de √âxito**:
- Registro/Login: <3 minutos
- Encontrar datos de estaci√≥n: <30 segundos
- Cambiar a gr√°ficos: <20 segundos
- Interpretar calidad del agua: <1 minuto
- 4/5 usuarios completan todas las tareas sin ayuda

**M√©tricas**:
```
Usuario 1: Registro ___min, Ver estaci√≥n ___s, Gr√°ficos ___s, 30d ___s, Interpretar ___s
Usuario 2: [...]
...
Tasa de √©xito: _____ / 5
```

---

#### PT-010: Claridad de Informaci√≥n (System Usability Scale - SUS)
**Objetivo**: Evaluar la usabilidad percibida mediante cuestionario est√°ndar  
**Tipo**: Usabilidad

**Procedimiento**:
1. Despu√©s de PT-009, pedir a los usuarios completar SUS
2. Calcular puntuaci√≥n (0-100)

**Cuestionario SUS** (1=Totalmente en desacuerdo, 5=Totalmente de acuerdo):
1. Creo que me gustar√≠a usar esta app frecuentemente
2. Encontr√© la app innecesariamente compleja
3. Pens√© que la app era f√°cil de usar
4. Creo que necesitar√≠a ayuda t√©cnica para usar esta app
5. Encontr√© que las funciones estaban bien integradas
6. Pens√© que hab√≠a mucha inconsistencia en la app
7. Imagino que la mayor√≠a aprender√≠a a usar esta app r√°pidamente
8. Encontr√© la app muy inc√≥moda de usar
9. Me sent√≠ muy confiado usando la app
10. Necesit√© aprender muchas cosas antes de poder usar la app

**Criterios de √âxito**:
- Puntuaci√≥n SUS: ‚â•70 (por encima del promedio)
- Puntuaci√≥n SUS: ‚â•80 (excelente)

**M√©tricas**:
```
Puntuaci√≥n SUS promedio: _____ / 100
Rango: _____ - _____
Usuarios con SUS ‚â•70: _____ / 5
```

---

#### PT-011: Test de 5 Segundos (First Impression)
**Objetivo**: Validar que la jerarqu√≠a visual es clara  
**Tipo**: Usabilidad

**Procedimiento**:
1. Mostrar screenshot del Dashboard a 10 personas por 5 segundos
2. Ocultar imagen
3. Preguntar:
   - ¬øQu√© informaci√≥n viste?
   - ¬øCu√°l era el estado del agua?
   - ¬øCu√°ntas estaciones hab√≠a?
   - ¬øRecuerdas alg√∫n valor num√©rico?

**Criterios de √âxito**:
- 8/10 identifican que es monitoreo de agua
- 7/10 recuerdan que hay 3 estaciones
- 6/10 notan los indicadores de estado (colores/iconos)
- 5/10 recuerdan al menos 1 valor (pH, TDS, etc.)

**M√©tricas**:
```
Identifican prop√≥sito: _____ / 10
Recuerdan estaciones: _____ / 10
Notan indicadores: _____ / 10
Recuerdan valores: _____ / 10
```

---

### 2.2 Pruebas de Accesibilidad

#### PT-012: Accesibilidad para Daltonismo
**Objetivo**: Verificar que los colores no son la √∫nica forma de distinguir estados  
**Tipo**: Accesibilidad

**Procedimiento**:
1. Usar simulador de daltonismo (Chrome DevTools > Rendering > Emulate vision deficiencies)
2. Probar Protanopia (rojo-verde), Deuteranopia, Tritanopia
3. Verificar que los estados siguen siendo distinguibles

**Criterios de √âxito**:
- Estados distinguibles sin depender del color
- Iconos presentes: ‚úì (bueno), ‚ö† (advertencia), ‚úó (malo)
- Texto descriptivo complementa los colores
- Contraste de texto: ‚â•4.5:1 (WCAG AA)

**M√©tricas**:
```
Distinguibilidad sin color: S√≠ / No
Iconos presentes en todos los estados: S√≠ / No
Contraste de texto: _____ :1
Cumple WCAG AA: S√≠ / No
```

---

#### PT-013: Navegaci√≥n con Teclado/TalkBack
**Objetivo**: Validar accesibilidad para usuarios con discapacidades  
**Tipo**: Accesibilidad

**Procedimiento**:
1. **Android**: Activar TalkBack (Accesibilidad > TalkBack)
2. **iOS**: Activar VoiceOver
3. Intentar completar las tareas:
   - Login
   - Ver datos de estaci√≥n
   - Cambiar a gr√°ficos
   - Seleccionar per√≠odo de 30 d√≠as
4. Sin tocar la pantalla (solo navegaci√≥n por voz)

**Criterios de √âxito**:
- Todos los elementos tienen etiquetas descriptivas
- Orden de navegaci√≥n l√≥gico (top ‚Üí bottom, left ‚Üí right)
- Botones anuncian su funci√≥n claramente
- Gr√°ficos tienen descripci√≥n textual alternativa
- Completar flujo principal sin bloqueos

**M√©tricas**:
```
Elementos sin etiqueta: _____ (debe ser 0)
Orden de navegaci√≥n l√≥gico: S√≠ / No
Descripci√≥n de gr√°ficos: S√≠ / No
Flujo completado: S√≠ / No
```

---

#### PT-014: Tama√±o de Elementos T√°ctiles
**Objetivo**: Verificar que los botones son suficientemente grandes  
**Tipo**: Accesibilidad + Usabilidad

**Procedimiento**:
1. Usar herramienta de medici√≥n (DevTools > Ruler)
2. Medir dimensiones de elementos interactivos:
   - Botones de login/registro
   - Tabs de Dashboard/Gr√°ficos
   - Selectores de per√≠odo (24h, 7d, 30d, 90d)
   - Dropdown de estaciones

**Criterios de √âxito**:
- Todos los elementos: ‚â•44x44 dp (recomendaci√≥n Material Design)
- Separaci√≥n entre elementos: ‚â•8 dp
- Elementos t√°ctiles no se superponen

**M√©tricas**:
```
Botones principales: _____ x _____ dp
Tabs: _____ x _____ dp
Selectores: _____ x _____ dp
Elementos <44dp: _____ (debe ser 0)
```

---

### 2.3 Pruebas de Experiencia Multiplataforma

#### PT-015: Consistencia Android vs iOS vs Windows
**Objetivo**: Validar que la experiencia es consistente en todas las plataformas  
**Tipo**: Usabilidad Multiplataforma

**Procedimiento**:
1. Ejecutar app en:
   - Android (tel√©fono)
   - iOS (iPhone o simulador)
   - Windows (desktop)
2. Comparar:
   - Layout de pantallas
   - Funcionalidad de botones
   - Rendimiento de gr√°ficos
   - Comportamiento de navegaci√≥n

**Criterios de √âxito**:
- Layout adaptado correctamente a cada plataforma
- Funcionalidad 100% id√©ntica
- Rendimiento similar (¬±10% de FPS)
- Navegaci√≥n respeta convenciones de cada plataforma

**M√©tricas**:
```
Diferencias visuales significativas: _____ (debe ser 0)
Funcionalidad diferente: _____ (debe ser 0)
FPS Android: _____, iOS: _____, Windows: _____
Navegaci√≥n nativa: S√≠ / No
```

---

#### PT-016: Adaptaci√≥n a Diferentes Tama√±os de Pantalla
**Objetivo**: Verificar responsividad en dispositivos diversos  
**Tipo**: Usabilidad

**Procedimiento**:
1. Probar en dispositivos:
   - Smartphone peque√±o (4.7", 360x640)
   - Smartphone grande (6.5", 1080x2400)
   - Tablet (10", 1200x1920)
   - Desktop (1920x1080)
2. Verificar que todo el contenido es visible sin scroll horizontal
3. Validar que los gr√°ficos se adaptan correctamente

**Criterios de √âxito**:
- Sin scroll horizontal en ninguna pantalla
- Gr√°ficos legibles en todas las resoluciones
- Texto no truncado ni solapado
- Botones accesibles sin necesidad de zoom

**M√©tricas**:
```
Scroll horizontal necesario: S√≠ / No
Gr√°ficos adaptados: S√≠ / No
Texto legible sin zoom: S√≠ / No
Layout roto: S√≠ / No
```

---

## 3. Pruebas Exploratorias Recomendadas

### 3.1 Escenarios de Uso Real

#### PT-017: Monitoreo Durante una Semana Completa
**Objetivo**: Validar estabilidad a largo plazo  
**Tipo**: Prueba de Duraci√≥n

**Procedimiento**:
1. Instalar app en dispositivo de uso diario
2. Dejar funcionando 7 d√≠as seguidos
3. Revisar diariamente:
   - App sigue respondiendo
   - Datos se actualizan correctamente
   - Firebase tiene todas las lecturas esperadas
4. Analizar logs de errores

**Criterios de √âxito**:
- App no se cierra inesperadamente en 7 d√≠as
- Firebase contiene ~60 lecturas/d√≠a por estaci√≥n (2/hora √ó 24h)
- Sin degradaci√≥n de rendimiento perceptible
- Bater√≠a: consumo <5% del total (en modo background)

**M√©tricas**:
```
Crashes en 7 d√≠as: _____ (debe ser 0)
Lecturas esperadas: _____ (60/d√≠a √ó 3 estaciones √ó 7 d√≠as = 1260)
Lecturas registradas: _____
Consumo de bater√≠a: _____ %
```

---

#### PT-018: Alternancia R√°pida de Conexi√≥n
**Objetivo**: Probar resiliencia ante conexi√≥n inestable  
**Tipo**: Estr√©s + Resiliencia

**Procedimiento**:
1. Iniciar app con WiFi activo
2. Durante 10 minutos, alternar cada 30 segundos:
   - WiFi ON ‚Üí OFF ‚Üí ON
   - Datos m√≥viles ON ‚Üí OFF ‚Üí ON
3. Verificar:
   - App no se cuelga
   - Datos se sincronizan correctamente al reconectar
   - UI muestra estado de conexi√≥n (si aplica)

**Criterios de √âxito**:
- Sin crashes durante 10 minutos
- Todas las lecturas offline se sincronizan
- Tiempo de sincronizaci√≥n post-reconexi√≥n: <10s
- UI responde durante todo el proceso

**M√©tricas**:
```
Crashes: _____ (debe ser 0)
Lecturas perdidas: _____ (debe ser 0)
Tiempo m√°x de sincronizaci√≥n: _____ s
UI bloqueada: S√≠ / No
```

---

#### PT-019: M√∫ltiples Usuarios Simult√°neos
**Objetivo**: Validar que el sistema soporta concurrencia  
**Tipo**: Carga + Concurrencia

**Procedimiento**:
1. Registrar 10 cuentas de usuario
2. Abrir app en 10 dispositivos simult√°neamente (o emuladores)
3. Todos los usuarios:
   - Hacen login
   - Navegan por dashboard
   - Cargan gr√°ficos hist√≥ricos
4. Verificar que todos reciben datos correctos

**Criterios de √âxito**:
- Todos los usuarios logran hacer login
- Datos consistentes entre usuarios
- Sin errores de "too many connections"
- Rendimiento similar para todos los usuarios

**M√©tricas**:
```
Logins exitosos: _____ / 10
Errores de conexi√≥n: _____ (debe ser 0)
Tiempo de carga promedio: _____ s
Diferencias de datos: _____ (debe ser 0)
```

---

### 3.2 Pruebas de Casos Extremos

#### PT-020: Datos Fuera de Rango (Edge Cases)
**Objetivo**: Validar manejo de valores an√≥malos  
**Tipo**: Robustez

**Procedimiento**:
1. Modificar temporalmente `SensorSimulator` para generar valores extremos:
   - pH: -1, 0, 14, 15
   - TDS: 0, 1000, 10000
   - Turbidez: 0, 100, 1000
   - Temperatura: -10, 0, 50, 100
2. Verificar que la app:
   - No crashea
   - Muestra correctamente el estado (rojo)
   - Guarda los datos en Firebase
   - Gr√°ficos se renderizan sin errores

**Criterios de √âxito**:
- Sin crashes con valores extremos
- Estados de calidad correctos (todos rojos)
- Gr√°ficos muestran todos los valores sin cortar ejes
- Firebase acepta y almacena los valores

**M√©tricas**:
```
Crashes con valores extremos: _____ (debe ser 0)
Estados incorrectos: _____ (debe ser 0)
Gr√°ficos rotos: _____ (debe ser 0)
Datos guardados en Firebase: S√≠ / No
```

---

#### PT-021: Base de Datos Vac√≠a
**Objetivo**: Verificar comportamiento sin datos hist√≥ricos  
**Tipo**: Robustez

**Procedimiento**:
1. Crear nuevo proyecto Firebase (o limpiar datos)
2. Eliminar archivo CSV de assets
3. Ejecutar app
4. Verificar:
   - Login funciona
   - Dashboard muestra mensaje apropiado
   - Gr√°ficos muestran "Sin datos disponibles"
   - No hay crashes

**Criterios de √âxito**:
- App no crashea con DB vac√≠a
- Mensajes informativos claros ("No hay datos hist√≥ricos")
- UI no muestra widgets vac√≠os o con errores
- Al generar nuevas lecturas, UI se actualiza correctamente

**M√©tricas**:
```
Crashes: _____ (debe ser 0)
Mensajes informativos presentes: S√≠ / No
UI con errores visuales: S√≠ / No
Actualizaci√≥n tras generar datos: S√≠ / No
```

---

## 4. Sugerencias Adicionales de Pruebas

### 4.1 Pruebas de Seguridad

**PT-022: Validaci√≥n de Credenciales**
- Probar login con credenciales inv√°lidas
- Verificar mensajes de error claros
- Intentar SQL injection en campos (deber√≠a ser imposible con Firebase)
- Validar que contrase√±as d√©biles son rechazadas

**PT-023: Autenticaci√≥n y Tokens**
- Verificar que tokens JWT expiran correctamente
- Probar acceso sin login (debe redirigir a login)
- Validar que logout limpia sesi√≥n completamente

---

### 4.2 Pruebas de Localizaci√≥n (i18n)

**PT-024: Soporte Multiidioma** (si aplica)
- Verificar que textos en espa√±ol son correctos
- Probar cambio de idioma del sistema
- Validar que formato de fechas respeta locale

---

### 4.3 Pruebas de Actualizaci√≥n

**PT-025: Migraci√≥n de Versiones**
- Instalar versi√≥n anterior (si existe)
- Actualizar a versi√≥n actual
- Verificar que datos locales se migran correctamente
- Validar que no hay p√©rdida de informaci√≥n

---

## 5. Plan de Ejecuci√≥n de Pruebas

### Prioridad Alta (Cr√≠ticas para Release)
1. **PT-001**: Latencia de actualizaci√≥n ‚úÖ
2. **PT-002**: Sincronizaci√≥n Firebase ‚úÖ
3. **PT-003**: Persistencia offline ‚úÖ
4. **PT-009**: Tiempo de aprendizaje ‚úÖ
5. **PT-012**: Accesibilidad daltonismo ‚úÖ
6. **PT-017**: Monitoreo 7 d√≠as ‚úÖ

### Prioridad Media (Importantes)
7. **PT-004**: Consumo de memoria
8. **PT-005**: Rendimiento gr√°ficos
9. **PT-007**: Validaci√≥n umbrales
10. **PT-010**: SUS Score
11. **PT-013**: TalkBack/VoiceOver
12. **PT-015**: Consistencia multiplataforma

### Prioridad Baja (Opcionales)
13. **PT-011**: Test de 5 segundos
14. **PT-014**: Tama√±o elementos t√°ctiles
15. **PT-016**: Adaptaci√≥n pantallas
16. **PT-018**: Alternancia conexi√≥n
17. **PT-019**: M√∫ltiples usuarios
18. **PT-020**: Datos extremos
19. **PT-021**: Base de datos vac√≠a

---

## 6. Herramientas Recomendadas

### Para Pruebas de Rendimiento
- **Flutter DevTools**: An√°lisis de rendimiento y memoria
- **Android Studio Profiler**: CPU, memoria, red (Android)
- **Xcode Instruments**: An√°lisis de rendimiento (iOS)
- **Firebase Performance Monitoring**: M√©tricas en producci√≥n

### Para Pruebas de Usabilidad
- **Maze.design**: Test remoto de usabilidad
- **UserTesting.com**: Grabaci√≥n de sesiones de usuarios reales
- **Hotjar**: Heatmaps y grabaciones de sesi√≥n

### Para Pruebas de Accesibilidad
- **Accessibility Scanner** (Android)
- **Accessibility Inspector** (Xcode)
- **Chrome DevTools > Lighthouse**: Auditor√≠a de accesibilidad
- **Color Contrast Analyzer**: Verificar contraste WCAG

### Para Pruebas de Integraci√≥n
- **Firebase Console**: Monitoreo en tiempo real de datos
- **Flutter Integration Tests**: Automatizaci√≥n de flujos completos
- **Postman/Insomnia**: Pruebas de API (si aplica)

---

## 7. Formato de Reporte de Resultados

### Plantilla de Reporte por Prueba

```markdown
## [ID_PRUEBA] - [Nombre de la Prueba]

**Ejecutado por**: _____  
**Fecha**: _____  
**Plataforma**: Android / iOS / Windows  
**Versi√≥n de app**: _____  

### Resultados
- Criterio 1: ‚úÖ Aprobado / ‚ùå Fallido
- Criterio 2: ‚úÖ Aprobado / ‚ùå Fallido
- ...

### M√©tricas Obtenidas
- M√©trica 1: _____ (esperado: _____)
- M√©trica 2: _____ (esperado: _____)

### Observaciones
[Describir cualquier comportamiento inesperado, bugs encontrados, etc.]

### Evidencia
- Screenshot 1: [adjuntar]
- Video: [link]
- Logs: [adjuntar archivo]

### Estado Final
‚úÖ APROBADO / ‚ùå FALLIDO / ‚ö†Ô∏è APROBADO CON OBSERVACIONES
```

---

## 8. Criterios de Aceptaci√≥n Global

Para considerar el sistema listo para producci√≥n:

### Obligatorios (100% cumplimiento)
- ‚úÖ Todas las pruebas de Prioridad Alta aprobadas
- ‚úÖ Sin crashes en prueba de 7 d√≠as
- ‚úÖ Sincronizaci√≥n Firebase funcional (online + offline)
- ‚úÖ SUS Score ‚â•70

### Deseables (80% cumplimiento)
- üîµ 80% de pruebas de Prioridad Media aprobadas
- üîµ Rendimiento: FPS ‚â•55 en todos los dispositivos
- üîµ Accesibilidad: Cumple WCAG AA
- üîµ Tiempo de aprendizaje <5 minutos para usuarios nuevos

### Opcionales (mejora continua)
- üü¢ Pruebas de Prioridad Baja: feedback para futuras versiones
- üü¢ Optimizaciones de rendimiento adicionales
- üü¢ Mejoras de UX basadas en feedback de usuarios

---

**Versi√≥n del Documento**: 1.0  
**√öltima Actualizaci√≥n**: 26 de Noviembre, 2025  
**Responsable**: Equipo de QA - Water Quality Analyzer
